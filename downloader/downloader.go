package downloader

import (
	"compress/gzip"
	"context"
	"crypto/tls"
	"fmt"
	"scrago/request"
	"scrago/response"
	"io"
	"net/http"
	"net/url"
	"strings"
	"sync"
	"time"

	"github.com/andybalholm/brotli"
)

// Downloader ä¸‹è½½å™¨æ¥å£
type Downloader interface {
	Download(req *request.Request) (*response.Response, error)
	DownloadAsync(req *request.Request) <-chan *AsyncResult
	DownloadBatch(reqs []*request.Request) <-chan *AsyncResult
}

// AsyncResult å¼‚æ­¥ä¸‹è½½ç»“æœ
type AsyncResult struct {
	Request  *request.Request
	Response *response.Response
	Error    error
}

// HTTPDownloader HTTPä¸‹è½½å™¨
type HTTPDownloader struct {
	client   *http.Client
	userAgent string
}

// NewHTTPDownloader åˆ›å»ºHTTPä¸‹è½½å™¨
func NewHTTPDownloader() *HTTPDownloader {
	// åˆ›å»ºè‡ªå®šä¹‰Transport
	transport := &http.Transport{
		TLSClientConfig: &tls.Config{
			InsecureSkipVerify: true, // è·³è¿‡SSLéªŒè¯
		},
		MaxIdleConns:        100,
		MaxIdleConnsPerHost: 10,
		IdleConnTimeout:     90 * time.Second,
	}
	
	client := &http.Client{
		Transport: transport,
		Timeout:   30 * time.Second,
		CheckRedirect: func(req *http.Request, via []*http.Request) error {
			// é»˜è®¤è·Ÿéšé‡å®šå‘ï¼Œæœ€å¤š10æ¬¡
			if len(via) >= 10 {
				return fmt.Errorf("stopped after 10 redirects")
			}
			return nil
		},
	}
	
	return &HTTPDownloader{
		client:    client,
		userAgent: "Go-Scrapy/1.0",
	}
}

// Download ä¸‹è½½è¯·æ±‚
func (d *HTTPDownloader) Download(req *request.Request) (*response.Response, error) {
	// åˆ›å»ºHTTPè¯·æ±‚
	httpReq, err := d.buildHTTPRequest(req)
	if err != nil {
		return nil, fmt.Errorf("build request failed: %w", err)
	}
	
	// åˆ›å»ºç‹¬ç«‹çš„å®¢æˆ·ç«¯å‰¯æœ¬ä»¥é¿å…å¹¶å‘é—®é¢˜
	client := &http.Client{
		Transport: d.client.Transport,
		Timeout:   10 * time.Second, // å‡å°‘è¶…æ—¶æ—¶é—´ä»¥å¿«é€Ÿå‘ç°é—®é¢˜
		CheckRedirect: d.client.CheckRedirect,
	}
	
	// è®¾ç½®ä»£ç†
	if req.Proxy != "" {
		proxyURL, err := url.Parse(req.Proxy)
		if err != nil {
			return nil, fmt.Errorf("invalid proxy URL: %w", err)
		}
		
		// åˆ›å»ºç‹¬ç«‹çš„transportå‰¯æœ¬
		transport := d.client.Transport.(*http.Transport).Clone()
		transport.Proxy = http.ProxyURL(proxyURL)
		client.Transport = transport
	}
	
	// è®¾ç½®è¶…æ—¶ï¼ˆç°åœ¨æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼‰
	if req.Timeout > 0 {
		client.Timeout = req.Timeout
	}
	
	// æ·»åŠ ç½‘ç»œè¯Šæ–­æ—¥å¿—
	fmt.Printf("ğŸŒ å¼€å§‹æ‰§è¡ŒHTTPè¯·æ±‚: %s\n", req.URL)
	start := time.Now()
	
	// æ‰§è¡Œè¯·æ±‚
	httpResp, err := client.Do(httpReq)
	if err != nil {
		fmt.Printf("âŒ HTTPè¯·æ±‚å¤±è´¥ (%v): %s - %v\n", time.Since(start), req.URL, err)
		return nil, fmt.Errorf("request failed: %w", err)
	}
	defer httpResp.Body.Close()
	
	fmt.Printf("âœ… HTTPè¯·æ±‚æˆåŠŸ (%v): %s - çŠ¶æ€ç : %d\n", time.Since(start), req.URL, httpResp.StatusCode)
	
	// æ£€æŸ¥å¹¶å¤„ç†å‹ç¼©çš„å“åº”
	var bodyReader io.Reader = httpResp.Body
	contentEncoding := httpResp.Header.Get("Content-Encoding")
	
	switch contentEncoding {
	case "gzip":
		fmt.Printf("ğŸ—œï¸  æ£€æµ‹åˆ°gzipå‹ç¼©ï¼Œæ­£åœ¨è§£å‹ç¼©: %s\n", req.URL)
		gzipReader, err := gzip.NewReader(httpResp.Body)
		if err != nil {
			fmt.Printf("âŒ gzipè§£å‹ç¼©å¤±è´¥: %s - %v\n", req.URL, err)
			return nil, fmt.Errorf("gzip decompression failed: %w", err)
		}
		defer gzipReader.Close()
		bodyReader = gzipReader
	case "br":
		fmt.Printf("ğŸ—œï¸  æ£€æµ‹åˆ°Brotliå‹ç¼©ï¼Œæ­£åœ¨è§£å‹ç¼©: %s\n", req.URL)
		bodyReader = brotli.NewReader(httpResp.Body)
	}
	
	// è¯»å–å“åº”ä½“
	body, err := io.ReadAll(bodyReader)
	if err != nil {
		fmt.Printf("âŒ è¯»å–å“åº”ä½“å¤±è´¥: %s - %v\n", req.URL, err)
		return nil, fmt.Errorf("read response body failed: %w", err)
	}
	
	fmt.Printf("ğŸ“„ å“åº”ä½“è¯»å–å®Œæˆ: %s - å¤§å°: %d bytes (ç¼–ç : %s)\n", req.URL, len(body), contentEncoding)
	
	// åˆ›å»ºå“åº”å¯¹è±¡
	resp := response.NewResponse(
		httpResp.Request.URL.String(),
		httpResp.StatusCode,
		httpResp.Header,
		body,
		req,
	)
	
	return resp, nil
}

// buildHTTPRequest æ„å»ºHTTPè¯·æ±‚
func (d *HTTPDownloader) buildHTTPRequest(req *request.Request) (*http.Request, error) {
	var body io.Reader
	if len(req.Body) > 0 {
		body = strings.NewReader(string(req.Body))
	}
	
	httpReq, err := http.NewRequest(req.Method, req.URL, body)
	if err != nil {
		return nil, err
	}
	
	// è®¾ç½®è¯·æ±‚å¤´
	for key, values := range req.Headers {
		for _, value := range values {
			httpReq.Header.Add(key, value)
		}
	}
	
	// è®¾ç½®é»˜è®¤User-Agentï¼ˆå¦‚æœæ²¡æœ‰è®¾ç½®çš„è¯ï¼‰
	if httpReq.Header.Get("User-Agent") == "" {
		httpReq.Header.Set("User-Agent", d.userAgent)
	}
	
	// è®¾ç½®Cookies
	for _, cookie := range req.Cookies {
		httpReq.AddCookie(cookie)
	}
	
	return httpReq, nil
}

// SetUserAgent è®¾ç½®User-Agent
func (d *HTTPDownloader) SetUserAgent(userAgent string) {
	d.userAgent = userAgent
}

// SetTimeout è®¾ç½®è¶…æ—¶æ—¶é—´
func (d *HTTPDownloader) SetTimeout(timeout time.Duration) {
	d.client.Timeout = timeout
}

// SetProxy è®¾ç½®ä»£ç†
func (d *HTTPDownloader) SetProxy(proxyURL string) error {
	if proxyURL == "" {
		// æ¸…é™¤ä»£ç†
		transport := d.client.Transport.(*http.Transport)
		transport.Proxy = nil
		return nil
	}
	
	proxy, err := url.Parse(proxyURL)
	if err != nil {
		return fmt.Errorf("invalid proxy URL: %w", err)
	}
	
	transport := d.client.Transport.(*http.Transport)
	transport.Proxy = http.ProxyURL(proxy)
	
	return nil
}

// EnableCookieJar å¯ç”¨Cookieç®¡ç†
func (d *HTTPDownloader) EnableCookieJar() {
	// è¿™é‡Œå¯ä»¥å®ç°Cookie JaråŠŸèƒ½
	// d.client.Jar = cookiejar.New(nil)
}

// SetTLSConfig è®¾ç½®TLSé…ç½®
func (d *HTTPDownloader) SetTLSConfig(config *tls.Config) {
	transport := d.client.Transport.(*http.Transport)
	transport.TLSClientConfig = config
}

// DownloadAsync å¼‚æ­¥ä¸‹è½½å•ä¸ªè¯·æ±‚
func (d *HTTPDownloader) DownloadAsync(req *request.Request) <-chan *AsyncResult {
	resultChan := make(chan *AsyncResult, 1)
	
	go func() {
		defer close(resultChan)
		
		resp, err := d.Download(req)
		resultChan <- &AsyncResult{
			Request:  req,
			Response: resp,
			Error:    err,
		}
	}()
	
	return resultChan
}

// DownloadBatch æ‰¹é‡å¼‚æ­¥ä¸‹è½½è¯·æ±‚
func (d *HTTPDownloader) DownloadBatch(reqs []*request.Request) <-chan *AsyncResult {
	resultChan := make(chan *AsyncResult, len(reqs))
	
	var wg sync.WaitGroup
	
	fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šåˆ›å»ºç¼“å†²é€šé“ï¼Œå®¹é‡ %d\n", len(reqs))
	fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šå‡†å¤‡å¯åŠ¨ %d ä¸ªå¹¶å‘è¯·æ±‚\n", len(reqs))
	
	// ğŸš€ å¼‚æ­¥å‘é€æ‰€æœ‰è¯·æ±‚
	for i, req := range reqs {
		wg.Add(1)
		fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šå¯åŠ¨ goroutine %d for URL: %s\n", i+1, req.URL)
		
		go func(index int, r *request.Request) {
			defer wg.Done()
			
			fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼š[%d] å¼€å§‹å¤„ç†è¯·æ±‚: %s\n", index+1, r.URL)
			
			// å¼‚æ­¥ä¸‹è½½
			resp, err := d.Download(r)
			
			var statusCode int
			if resp != nil {
				statusCode = resp.StatusCode
			}
			
			fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼š[%d] è¯·æ±‚å®Œæˆ: %s (çŠ¶æ€ç : %d, é”™è¯¯: %v)\n", index+1, r.URL, statusCode, err)
			
			// å‘é€ç»“æœåˆ°é€šé“
			result := &AsyncResult{
				Request:  r,
				Response: resp,
				Error:    err,
			}
			
			fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼š[%d] å‘é€ç»“æœåˆ°é€šé“: %s\n", index+1, r.URL)
			resultChan <- result
			fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼š[%d] ç»“æœå·²å‘é€: %s\n", index+1, r.URL)
		}(i, req)
	}
	
	// ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆåå…³é—­é€šé“
	go func() {
		fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆ...\n")
		wg.Wait()
		fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šæ‰€æœ‰è¯·æ±‚å®Œæˆï¼Œå…³é—­é€šé“\n")
		close(resultChan)
		fmt.Printf("ğŸ”§ ä¸‹è½½å™¨ï¼šé€šé“å·²å…³é—­\n")
	}()
	
	return resultChan
}

// DownloadBatchWithContext å¸¦ä¸Šä¸‹æ–‡çš„æ‰¹é‡å¼‚æ­¥ä¸‹è½½
func (d *HTTPDownloader) DownloadBatchWithContext(ctx context.Context, reqs []*request.Request) <-chan *AsyncResult {
	resultChan := make(chan *AsyncResult, len(reqs))
	
	var wg sync.WaitGroup
	
	// ğŸš€ å¼‚æ­¥å‘é€æ‰€æœ‰è¯·æ±‚
	for _, req := range reqs {
		wg.Add(1)
		go func(r *request.Request) {
			defer wg.Done()
			
			select {
			case <-ctx.Done():
				// ä¸Šä¸‹æ–‡å–æ¶ˆ
				resultChan <- &AsyncResult{
					Request:  r,
					Response: nil,
					Error:    ctx.Err(),
				}
				return
			default:
				// å¼‚æ­¥ä¸‹è½½
				resp, err := d.Download(r)
				
				// å‘é€ç»“æœåˆ°é€šé“
				select {
				case resultChan <- &AsyncResult{
					Request:  r,
					Response: resp,
					Error:    err,
				}:
				case <-ctx.Done():
					// ä¸Šä¸‹æ–‡å–æ¶ˆï¼Œä¸¢å¼ƒç»“æœ
				}
			}
		}(req)
	}
	
	// ç­‰å¾…æ‰€æœ‰è¯·æ±‚å®Œæˆåå…³é—­é€šé“
	go func() {
		wg.Wait()
		close(resultChan)
	}()
	
	return resultChan
}